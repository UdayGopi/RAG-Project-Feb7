# ğŸš€ Production-Grade RAG Application

A modular, scalable, cloud-ready Retrieval-Augmented Generation (RAG) system built with modern best practices.

## âœ¨ Key Features

### ğŸ—ï¸ Production Architecture
- **Modular Design**: Clean separation of concerns across 10+ modules
- **Cloud-Ready**: Seamless switching between local and S3/Azure storage
- **Multi-Tenant**: Isolated data and indexes per tenant
- **Scalable**: Horizontal and vertical scaling support

### ğŸ¤– Advanced RAG
- **Hybrid Retrieval**: Combines semantic (embeddings) and keyword (BM25) search
- **Query Expansion**: HyDE, multi-query, and synonym expansion
- **Smart Reranking**: Cross-encoder reranking for precision
- **Metadata Filtering**: Pre-filter documents by type, tenant, date
- **Context Management**: Intelligent token-aware context truncation

### ğŸ”Œ Flexible Models
- **Multiple LLM Providers**: Groq, OpenAI, Anthropic, Ollama
- **Multiple Embeddings**: HuggingFace, OpenAI, Cohere
- **Hot-Swapping**: Switch models without restart
- **Model Registry**: Central catalog of available models
- **Lazy Loading**: Load models on-demand for efficiency

### ğŸ’¾ Storage Options
- **Local**: Filesystem storage for development
- **AWS S3**: Production cloud storage with versioning
- **Azure Blob**: Alternative cloud storage
- **Hybrid**: Local cache with cloud backup

### ğŸ” Security & Auth
- **JWT Authentication**: Secure API access
- **OAuth 2.0**: Google and Microsoft login
- **Role-Based Access**: Admin and user roles
- **Tenant Isolation**: Data segregation

### ğŸ“Š Monitoring
- **Structured Logging**: JSON logs for easy parsing
- **Metrics**: Query latency, error rates, usage stats
- **Health Checks**: Kubernetes-ready health endpoints
- **CloudWatch Integration**: AWS native monitoring

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- pip or conda
- Groq API key (free at https://groq.com)

### Local Development

```bash
# Clone repository
git clone <your-repo-url>
cd Rag-Project

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
nano .env  # Add your GROQ_API_KEY

# Run application
python app.py
```

Access at: **http://localhost:5001**

### Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f app

# Stop
docker-compose down
```

## ğŸ“ Project Structure

```
Rag-Project/
â”‚
â”œâ”€â”€ config/                    # ğŸ”§ Configuration
â”‚   â”œâ”€â”€ settings.py           # Centralized settings
â”‚   â”œâ”€â”€ models.py             # Model configurations
â”‚   â”œâ”€â”€ storage.py            # Storage configs
â”‚   â””â”€â”€ constants.py          # App constants
â”‚
â”œâ”€â”€ core/                      # ğŸ¤– Core RAG Components
â”‚   â”œâ”€â”€ llm.py                # LLM management
â”‚   â”œâ”€â”€ embeddings.py         # Embedding models
â”‚   â”œâ”€â”€ chunking.py           # Document chunking
â”‚   â””â”€â”€ reranking.py          # Reranking models
â”‚
â”œâ”€â”€ agents/                    # ğŸ§  Agent Logic
â”‚   â”œâ”€â”€ rag_agent.py          # Main RAG agent
â”‚   â”œâ”€â”€ query_router.py       # Multi-tenant routing
â”‚   â””â”€â”€ intent_classifier.py  # Intent detection
â”‚
â”œâ”€â”€ storage/                   # ğŸ’¾ Storage Abstraction
â”‚   â”œâ”€â”€ base.py               # Storage interface
â”‚   â”œâ”€â”€ local_storage.py      # Local filesystem
â”‚   â”œâ”€â”€ s3_storage.py         # AWS S3
â”‚   â””â”€â”€ factory.py            # Storage factory
â”‚
â”œâ”€â”€ retrieval/                 # ğŸ” Advanced Retrieval
â”‚   â”œâ”€â”€ hybrid_search.py      # BM25 + Semantic
â”‚   â”œâ”€â”€ query_expansion.py    # Query rewriting
â”‚   â”œâ”€â”€ rag_fusion.py         # Multi-query fusion
â”‚   â””â”€â”€ filters.py            # Metadata filtering
â”‚
â”œâ”€â”€ models/                    # ğŸ“¦ Model Management
â”‚   â”œâ”€â”€ model_registry.py     # Available models
â”‚   â”œâ”€â”€ model_loader.py       # Lazy loading
â”‚   â””â”€â”€ model_cache.py        # Model caching
â”‚
â”œâ”€â”€ ingestion/                 # ğŸ“„ Document Processing
â”‚   â”œâ”€â”€ processors.py         # PDF, DOCX parsers
â”‚   â”œâ”€â”€ extractors.py         # Table extraction
â”‚   â””â”€â”€ web_scraper.py        # URL ingestion
â”‚
â”œâ”€â”€ database/                  # ğŸ’½ Data Layer
â”‚   â”œâ”€â”€ users.py              # User management
â”‚   â””â”€â”€ cache.py              # Response caching
â”‚
â”œâ”€â”€ api/                       # ğŸŒ API Routes
â”‚   â”œâ”€â”€ auth.py               # Authentication
â”‚   â”œâ”€â”€ chat.py               # Chat endpoints
â”‚   â””â”€â”€ upload.py             # File upload
â”‚
â”œâ”€â”€ utils/                     # ğŸ› ï¸ Utilities
â”‚   â”œâ”€â”€ logging.py            # Custom logging
â”‚   â””â”€â”€ metrics.py            # Metrics tracking
â”‚
â”œâ”€â”€ static/                    # ğŸ¨ Frontend
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ care-policy-hub.html
â”‚
â”œâ”€â”€ docs/                      # ğŸ“š Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT.md         # Deployment guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md       # System architecture
â”‚   â””â”€â”€ MIGRATION.md          # Migration guide
â”‚
â”œâ”€â”€ app.py                     # ğŸšª Main application
â”œâ”€â”€ requirements.txt           # ğŸ“¦ Dependencies
â”œâ”€â”€ Dockerfile                 # ğŸ³ Docker config
â”œâ”€â”€ docker-compose.yml         # ğŸ³ Compose config
â””â”€â”€ .env.example               # âš™ï¸ Environment template
```

## âš™ï¸ Configuration

### Environment Variables

Key settings in `.env`:

```bash
# Storage Backend
STORAGE_BACKEND=local  # or 's3', 'azure'

# LLM Provider
LLM_PROVIDER=groq      # or 'openai', 'anthropic', 'ollama'
LLM_MODEL=llama-3.1-8b-instant

# Embedding Provider
EMBEDDING_PROVIDER=huggingface  # or 'openai', 'cohere'
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Retrieval Strategy
RETRIEVAL_MODE=semantic  # or 'hybrid', 'fusion'
ENABLE_QUERY_EXPANSION=false
```

### Switching to Cloud Storage (S3)

```bash
# In .env
STORAGE_BACKEND=s3
S3_BUCKET=your-bucket-name
AWS_REGION=us-east-1
# Leave AWS keys empty to use IAM role
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
```

### Switching LLM Provider

```bash
# Use OpenAI
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo-preview
OPENAI_API_KEY=your_openai_key

# Use Anthropic
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=your_anthropic_key

# Use Local Ollama
LLM_PROVIDER=ollama
LLM_MODEL=llama3
```

## ğŸ” Advanced RAG Features

### 1. Hybrid Search

Combines semantic and keyword search for better results:

```python
# Enable in .env
RETRIEVAL_MODE=hybrid
```

### 2. Query Expansion

Generate multiple query variations:

```python
# Enable in .env
ENABLE_QUERY_EXPANSION=true
QUERY_EXPANSION_COUNT=2
```

### 3. Metadata Filtering

Filter by document type, tenant, date:

```python
from retrieval.filters import MetadataFilter

# In your code
filters = MetadataFilter.create_tenant_filter("HIH")
```

### 4. Context Truncation

Smart token-aware context management:

```python
# Configure in .env
MAX_CONTEXT_TOKENS=3500
MAX_PROMPT_TOKENS=5500
```

## ğŸš€ Deployment

### Local Development

```bash
python app.py
```

### Production with Gunicorn

```bash
gunicorn --bind 0.0.0.0:8000 --workers 4 --timeout 300 app:app
```

### Docker

```bash
docker build -t rag-app .
docker run -p 5001:5001 --env-file .env rag-app
```

### AWS EC2

See [DEPLOYMENT.md](docs/DEPLOYMENT.md) for complete guide.

## ğŸ“Š API Endpoints

### Authentication

```bash
# Sign in
POST /auth/signin
{
  "email": "user@example.com",
  "password": "password"
}

# Sign up
POST /auth/signup
{
  "name": "John Doe",
  "email": "user@example.com",
  "password": "password"
}
```

### Chat

```bash
# Send query
POST /chat
{
  "query": "What are the HIH onboarding steps?",
  "tenant_id": "HIH"  # optional
}

# Response
{
  "summary": "...",
  "detailed_response": "...",
  "sources": [...],
  "confidence": 0.92
}
```

### Upload

```bash
# Upload document
POST /upload
Content-Type: multipart/form-data
- file: document.pdf
- tenant_id: HIH
```

## ğŸ§ª Testing

```bash
# Run tests
pytest

# With coverage
pytest --cov=. --cov-report=html

# Specific test
pytest tests/test_rag_agent.py
```

## ğŸ“ˆ Monitoring

### Health Check

```bash
GET /health

# Response
{
  "status": "healthy",
  "version": "2.0.0",
  "storage": "local"
}
```

### Logs

```bash
# View logs
tail -f logs/app.log

# Docker logs
docker logs -f rag-app
```

## ğŸ”§ Troubleshooting

### Common Issues

**1. Module not found**
```bash
pip install -r requirements.txt --force-reinstall
```

**2. S3 permission denied**
- Check AWS credentials
- Verify IAM role permissions
- Test with AWS CLI: `aws s3 ls s3://your-bucket`

**3. Model loading slow**
- First load downloads model (~100-500MB)
- Subsequent loads use cache
- Use smaller models: `EMBEDDING_MODEL=BAAI/bge-small-en-v1.5`

**4. Out of memory**
- Reduce workers: `gunicorn --workers 2`
- Use smaller chunk size: `CHUNK_SIZE=512`
- Use lighter models

## ğŸ¯ Roadmap

- [ ] Agentic RAG (iterative retrieval)
- [ ] Multi-modal support (images, tables)
- [ ] GraphRAG integration
- [ ] Real-time streaming
- [ ] Advanced caching (Redis)
- [ ] A/B testing framework
- [ ] Fine-tuned models
- [ ] Federated search

## ğŸ“š Documentation

- [Architecture](docs/ARCHITECTURE.md) - System design and components
- [Deployment](docs/DEPLOYMENT.md) - Deployment guides for AWS, Docker
- [Migration](docs/MIGRATION.md) - Migrate from old structure
- [API Documentation](docs/API.md) - Detailed API reference

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ’¡ Support

- **Issues**: Open GitHub issue
- **Docs**: Check [docs/](docs/) folder
- **Email**: your-email@example.com

---

**Built with â¤ï¸ for production-grade RAG applications**
